{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import imageio as magic\n",
    "import pandas as pd\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogisticRegression:\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"Logistic Regression\")\n",
    "\n",
    "    def get_sigmoid(self, X, W):\n",
    "        return 1 / (1 + np.exp(- self.get_hypothesis(X, W)))\n",
    "\n",
    "    def get_hypothesis(self, X, W):\n",
    "        return X @ W.T\n",
    "\n",
    "    def __get_cost(self, X, Y, W, lamda):\n",
    "        return -(1.0 / len(X)) * (np.sum((Y * np.log(self.get_sigmoid(X, W))) + ((1 - Y) * np.log(1 - self.get_sigmoid(X, W)))) - lamda)\n",
    "\n",
    "    def __get_gradient(self, X, Y, W, lamda):\n",
    "        return (1.0 / len(X)) * (np.sum(X * (self.get_hypothesis(X,W) - Y), axis=0) + (lamda * np.sum(W)))\n",
    "\n",
    "    def __logistic_regression(self, X, Y, W, alpha, max_iterations, lamda):\n",
    "        \n",
    "        for i in range(max_iterations):\n",
    "            \n",
    "            W = W - alpha * self.__get_gradient(X, Y, W, lamda)\n",
    "            cost = self.__get_cost(X, Y, W, lamda)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(\"Cost: \", cost)\n",
    "            \n",
    "        return W, cost\n",
    "\n",
    "    def train(self, X, Y, W, alpha, max_iterations, lamda=0):\n",
    "        return self.__logistic_regression(X, Y, W, alpha, max_iterations, lamda)\n",
    "\n",
    "    def validate(self, X, Y, W):\n",
    "        return self.__get_cost(X, Y, W, 0)\n",
    "\n",
    "    def test(self, X, Y, W, lamda=0):\n",
    "        return self.__get_cost(X, Y, W, 0)\n",
    "    \n",
    "    def predict(self,X,W):\n",
    "        return self.get_sigmoid(X,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.582031</td>\n",
       "      <td>0.324219</td>\n",
       "      <td>0.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.164062</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.332031</td>\n",
       "      <td>0.105469</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.089844</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.804688</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.480469</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>0.417969</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.246094</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.339844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7    \\\n",
       "0  6.0  0.000000  0.046875  0.000000  0.003906  0.007812  0.031250  0.039062   \n",
       "1  6.0  0.003906  0.023438  0.011719  0.007812  0.015625  0.000000  0.000000   \n",
       "2  0.0  0.011719  0.109375  0.000000  0.046875  0.015625  0.000000  0.156250   \n",
       "3  4.0  0.089844  0.562500  0.929688  0.988281  0.984375  0.804688  0.187500   \n",
       "4  6.0  0.019531  0.027344  0.003906  0.000000  0.019531  0.027344  0.015625   \n",
       "\n",
       "        8         9      ...          775       776       777       778  \\\n",
       "0  0.218750  0.664062    ...     0.000000  0.000000  0.109375  0.277344   \n",
       "1  0.035156  0.000000    ...     0.062500  0.023438  0.164062  0.406250   \n",
       "2  0.304688  0.515625    ...     0.000000  0.000000  0.035156  0.000000   \n",
       "3  0.039062  0.000000    ...     0.503906  0.480469  0.406250  0.417969   \n",
       "4  0.027344  0.015625    ...     0.000000  0.312500  0.339844  0.000000   \n",
       "\n",
       "        779       780       781       782       783       784  \n",
       "0  0.421875  0.539062  0.730469  0.582031  0.324219  0.117188  \n",
       "1  0.332031  0.105469  0.011719  0.007812  0.003906  0.000000  \n",
       "2  0.000000  0.035156  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.421875  0.246094  0.109375  0.113281  0.015625  0.003906  \n",
       "4  0.011719  0.027344  0.007812  0.000000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image_data = []\n",
    "label = []\n",
    "for file_name in glob.iglob('/home/lognod/Desktop/nhcd/numerals/**/*.jpg', recursive=True):\n",
    "    image_array = magic.imread(file_name,as_gray=True)\n",
    "    label=int(file_name[-12:-11])\n",
    "    pixel_data = (255.0-image_array.flatten())/256.0\n",
    "    pixel_data = np.append(label,pixel_data)\n",
    "    image_data.append(pixel_data)\n",
    "\n",
    "\n",
    "image_data = np.array(image_data)\n",
    "np.random.shuffle(image_data)\n",
    "image_data_pd = pd.DataFrame(image_data)\n",
    "image_data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 785)\n",
      "[[6.]\n",
      " [6.]\n",
      " [0.]\n",
      " ...\n",
      " [3.]\n",
      " [0.]\n",
      " [5.]]\n"
     ]
    }
   ],
   "source": [
    "X = image_data_pd.iloc[:,1:]\n",
    "ones = np.ones([len(X),1])\n",
    "X = np.concatenate((ones,X), axis = 1)\n",
    "Y = image_data_pd.iloc[:,0:1].values\n",
    "print(X.shape)\n",
    "print(Y)\n",
    "X_train,X_rest,Y_train,Y_rest =  train_test_split(X,Y,test_size=0.4)\n",
    "X_validate,X_test,Y_validate,Y_test = train_test_split(X_rest,Y_rest,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728\n",
      "(1, 785)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])\n",
    "W = np.zeros((1,len(X_train[0,:])))\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Learning:  0.0\n",
      "Cost:  0.7114695611221895\n",
      "Learning:  1.0\n",
      "Cost:  0.7092414544955561\n",
      "Learning:  2.0\n",
      "Cost:  0.7094634392518312\n",
      "Learning:  3.0\n",
      "Cost:  0.7095644544662125\n",
      "Learning:  4.0\n",
      "Cost:  0.7081073839956243\n",
      "Learning:  5.0\n",
      "Cost:  0.7075633866432153\n",
      "Learning:  6.0\n",
      "Cost:  0.7080642813426173\n",
      "Learning:  7.0\n",
      "Cost:  0.7086935081319748\n",
      "Learning:  8.0\n",
      "Cost:  0.7063661614146622\n",
      "Learning:  9.0\n",
      "Cost:  0.7089755260545648\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "weight_list =[]\n",
    "cost_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    W = np.zeros((1,len(X_train[0,:])))\n",
    "    print(\"Learning: \", float(i))\n",
    "    Y_train_one = (Y_train == float(i)).astype(int)\n",
    "    weight,cost = logistic_regression.train(X_train,Y_train_one,W,0.01,100,0)\n",
    "    weight_list.append(weight.flatten())\n",
    "    cost_list.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 785)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.array(weight_list)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005805</td>\n",
       "      <td>-0.001008</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>-0.001812</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.000704</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>-0.001261</td>\n",
       "      <td>-0.001627</td>\n",
       "      <td>-0.001583</td>\n",
       "      <td>-0.001902</td>\n",
       "      <td>-0.002299</td>\n",
       "      <td>-0.002387</td>\n",
       "      <td>-0.002268</td>\n",
       "      <td>-0.001885</td>\n",
       "      <td>-0.000423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005526</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>-0.000585</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>-0.001439</td>\n",
       "      <td>-0.000886</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>-0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006165</td>\n",
       "      <td>-0.002173</td>\n",
       "      <td>-0.002818</td>\n",
       "      <td>-0.002960</td>\n",
       "      <td>-0.002694</td>\n",
       "      <td>-0.002695</td>\n",
       "      <td>-0.002923</td>\n",
       "      <td>-0.002754</td>\n",
       "      <td>-0.002083</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001154</td>\n",
       "      <td>-0.000940</td>\n",
       "      <td>-0.001140</td>\n",
       "      <td>-0.000839</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>-0.000883</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>0.001965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003363</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>-0.001796</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>-0.000872</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001879</td>\n",
       "      <td>-0.001159</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>0.007894</td>\n",
       "      <td>0.004266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.004248</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.003496</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>-0.001467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004528</td>\n",
       "      <td>0.003747</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>-0.001359</td>\n",
       "      <td>-0.002778</td>\n",
       "      <td>-0.003537</td>\n",
       "      <td>-0.001959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.005805 -0.001008 -0.002114 -0.001812 -0.000529 -0.000704 -0.000062   \n",
       "1  0.005526  0.000132 -0.000585 -0.001375 -0.001439 -0.000886 -0.000413   \n",
       "2  0.006165 -0.002173 -0.002818 -0.002960 -0.002694 -0.002695 -0.002923   \n",
       "3  0.003363 -0.001128 -0.001796 -0.001637 -0.000872  0.000024  0.001106   \n",
       "4  0.006847  0.003534  0.004248  0.004005  0.004640  0.003496  0.002499   \n",
       "\n",
       "        7         8         9      ...          775       776       777  \\\n",
       "0  0.000745  0.002024  0.003493    ...    -0.000544 -0.001261 -0.001627   \n",
       "1  0.000276  0.000186  0.000404    ...    -0.000107  0.000066 -0.000433   \n",
       "2 -0.002754 -0.002083 -0.001365    ...    -0.001154 -0.000940 -0.001140   \n",
       "3  0.001765  0.001766  0.001892    ...    -0.001879 -0.001159 -0.000575   \n",
       "4  0.001079  0.000273 -0.001467    ...     0.004528  0.003747  0.003893   \n",
       "\n",
       "        778       779       780       781       782       783       784  \n",
       "0 -0.001583 -0.001902 -0.002299 -0.002387 -0.002268 -0.001885 -0.000423  \n",
       "1 -0.000336  0.000039  0.000114  0.000024  0.000948  0.001407 -0.000031  \n",
       "2 -0.000839 -0.000694 -0.000883  0.000213  0.000639  0.002572  0.001965  \n",
       "3 -0.000529 -0.000527 -0.000077  0.000746  0.004805  0.007894  0.004266  \n",
       "4  0.003135  0.001390 -0.000293 -0.001359 -0.002778 -0.003537 -0.001959  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_data = pd.DataFrame(weights)\n",
    "weights_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_data.to_csv(\"/home/lognod/MiniML/mini_logistic_without_regularization.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 785)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.166438892252952"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(weights.shape)\n",
    "logistic_regression.validate(X_validate,Y_validate,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "weights_2 = pd.read_csv(\"/home/lognod/MiniML/mini_logistic_with_regularization.csv\")\n",
    "y =[]\n",
    "for i in range(10):\n",
    "    y.append(logistic_regression.predict(X_test[26,:],weights_2.iloc[i,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4953133191104629,\n",
       " 0.5173177685364324,\n",
       " 0.4884820586836548,\n",
       " 0.5324840126875459,\n",
       " 0.5138344148173045,\n",
       " 0.49708518115291883,\n",
       " 0.5781435215174765,\n",
       " 0.4967140471910474,\n",
       " 0.5050302815024996,\n",
       " 0.5213652776239386]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n"
     ]
    }
   ],
   "source": [
    "prediction = np.where(y == np.amax(y))\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_test[26,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "image = test.reshape(-1,28)\n",
    "magic.imwrite('/home/lognod/predicted.png', image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
