{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import imageio as magic\n",
    "import pandas as pd\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LogisticRegression:\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"Logistic Regression\")\n",
    "\n",
    "    def get_sigmoid(self, X, W):\n",
    "        return 1 / (1 + np.exp(- self.get_hypothesis(X, W)))\n",
    "\n",
    "    def get_hypothesis(self, X, W):\n",
    "        return X @ W.T\n",
    "\n",
    "    def __get_cost(self, X, Y, W, lamda):\n",
    "        return -(1.0 / len(X)) * (np.sum((Y * np.log(self.get_sigmoid(X, W))) + ((1 - Y) * np.log(1 - self.get_sigmoid(X, W)))) - lamda)\n",
    "\n",
    "    def __get_gradient(self, X, Y, W, lamda):\n",
    "        return (1.0 / len(X)) * (np.sum(X * (self.get_hypothesis(X,W) - Y), axis=0) + (lamda * np.sum(W)))\n",
    "\n",
    "    def __logistic_regression(self, X, Y, W, alpha, max_iterations, lamda):\n",
    "        \n",
    "        for i in range(max_iterations):\n",
    "            \n",
    "            W = W - alpha * self.__get_gradient(X, Y, W, lamda)\n",
    "            cost = self.__get_cost(X, Y, W, lamda)\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(\"Cost: \", cost)\n",
    "            \n",
    "        return W, cost\n",
    "\n",
    "    def train(self, X, Y, W, alpha, max_iterations, lamda=0):\n",
    "        return self.__logistic_regression(X, Y, W, alpha, max_iterations, lamda)\n",
    "\n",
    "    def validate(self, X, Y, W):\n",
    "        return self.__get_cost(X, Y, W, 0)\n",
    "\n",
    "    def test(self, X, Y, W, lamda=0):\n",
    "        return self.__get_cost(X, Y, W, 0)\n",
    "    \n",
    "    def predict(self,X,W):\n",
    "        return self.get_sigmoid(X,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.031373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086275</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.019608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7    \\\n",
       "0  7.0  0.000000  0.050980  0.007843  0.000000  0.007843  0.023529  0.023529   \n",
       "1  8.0  0.023529  0.031373  0.011765  0.023529  0.058824  0.003922  0.000000   \n",
       "2  9.0  0.003922  0.011765  0.007843  0.047059  0.062745  0.007843  0.000000   \n",
       "3  0.0  0.062745  0.000000  0.039216  0.000000  0.000000  0.027451  0.000000   \n",
       "4  3.0  0.000000  0.019608  0.000000  0.000000  0.007843  0.000000  0.000000   \n",
       "\n",
       "        8         9      ...          775       776       777       778  \\\n",
       "0  0.000000  0.000000    ...     0.027451  0.039216  0.062745  0.027451   \n",
       "1  0.007843  0.035294    ...     0.011765  0.015686  0.023529  0.027451   \n",
       "2  0.043137  0.066667    ...     0.003922  0.000000  0.043137  0.000000   \n",
       "3  0.023529  0.050980    ...     0.086275  0.011765  0.000000  0.000000   \n",
       "4  0.023529  0.043137    ...     0.000000  0.023529  0.050980  0.000000   \n",
       "\n",
       "        779       780       781       782       783       784  \n",
       "0  0.000000  0.023529  0.054902  0.015686  0.011765  0.031373  \n",
       "1  0.015686  0.003922  0.035294  0.000000  0.000000  0.035294  \n",
       "2  0.000000  0.003922  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.003922  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.105882  0.301961  0.317647  0.156863  0.019608  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image_data = []\n",
    "label = []\n",
    "for file_name in glob.iglob('/home/lognod/Desktop/nhcd/numerals/**/*.jpg', recursive=True):\n",
    "    image_array = magic.imread(file_name,as_gray=True)\n",
    "    label=int(file_name[-12:-11])\n",
    "    pixel_data = (255.0-image_array.flatten())/255.0\n",
    "    pixel_data = np.append(label,pixel_data)\n",
    "    image_data.append(pixel_data)\n",
    "\n",
    "\n",
    "image_data = np.array(image_data)\n",
    "np.random.shuffle(image_data)\n",
    "image_data_pd = pd.DataFrame(image_data)\n",
    "image_data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2880, 785)\n",
      "[[7.]\n",
      " [8.]\n",
      " [9.]\n",
      " ...\n",
      " [5.]\n",
      " [9.]\n",
      " [7.]]\n"
     ]
    }
   ],
   "source": [
    "X = image_data_pd.iloc[:,1:]\n",
    "ones = np.ones([len(X),1])\n",
    "X = np.concatenate((ones,X), axis = 1)\n",
    "Y = image_data_pd.iloc[:,0:1].values\n",
    "print(X.shape)\n",
    "print(Y)\n",
    "X_train,X_rest,Y_train,Y_rest =  train_test_split(X,Y,test_size=0.4)\n",
    "X_validate,X_test,Y_validate,Y_test = train_test_split(X_rest,Y_rest,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728\n",
      "(1, 785)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])\n",
    "W = np.zeros((1,len(X_train[0,:])))\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Learning:  0.0\n",
      "Cost:  0.7112669426043642\n",
      "Cost:  0.6822786553232426\n",
      "Cost:  0.6792615586015494\n",
      "Cost:  0.6780761537670915\n",
      "Learning:  1.0\n",
      "Cost:  0.710111432440517\n",
      "Cost:  0.6737549066782935\n",
      "Cost:  0.6716885234818998\n",
      "Cost:  0.6709051897954605\n",
      "Learning:  2.0\n",
      "Cost:  0.7081731466552008\n",
      "Cost:  0.702094505625266\n",
      "Cost:  0.698825565880226\n",
      "Cost:  0.6973888988849288\n",
      "Learning:  3.0\n",
      "Cost:  0.7096396298177997\n",
      "Cost:  0.7112105675462583\n",
      "Cost:  0.7071910342262131\n",
      "Cost:  0.7052697868441494\n",
      "Learning:  4.0\n",
      "Cost:  0.7085806395018179\n",
      "Cost:  0.6990266427031622\n",
      "Cost:  0.6947982657683732\n",
      "Cost:  0.6932019943367592\n",
      "Learning:  5.0\n",
      "Cost:  0.7073278372742765\n",
      "Cost:  0.7035979771118896\n",
      "Cost:  0.7000423842429321\n",
      "Cost:  0.6985020898276292\n",
      "Learning:  6.0\n",
      "Cost:  0.7079251821106157\n",
      "Cost:  0.6966139970910629\n",
      "Cost:  0.691777944592922\n",
      "Cost:  0.6901296136579679\n",
      "Learning:  7.0\n",
      "Cost:  0.7093863794352512\n",
      "Cost:  0.6891380583761313\n",
      "Cost:  0.6855259121549591\n",
      "Cost:  0.684238551378084\n",
      "Learning:  8.0\n",
      "Cost:  0.7066574429941835\n",
      "Cost:  0.682953369094733\n",
      "Cost:  0.678821053265874\n",
      "Cost:  0.6773072535823181\n",
      "Learning:  9.0\n",
      "Cost:  0.7080830078565913\n",
      "Cost:  0.697991508639581\n",
      "Cost:  0.6930027014261662\n",
      "Cost:  0.690615625322037\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "weight_list =[]\n",
    "cost_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    W = np.zeros((1,len(X_train[0,:])))\n",
    "    print(\"Learning: \", float(i))\n",
    "    Y_train_one = (Y_train == float(i)).astype(int)\n",
    "    weight,cost = logistic_regression.train(X_train,Y_train_one,W,0.01,300,0.01)\n",
    "    weight_list.append(weight.flatten())\n",
    "    cost_list.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 785)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.array(weight_list)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.017949</td>\n",
       "      <td>-0.003000</td>\n",
       "      <td>-0.004920</td>\n",
       "      <td>-0.002380</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>-0.000958</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>0.007890</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001189</td>\n",
       "      <td>-0.003185</td>\n",
       "      <td>-0.004328</td>\n",
       "      <td>-0.003749</td>\n",
       "      <td>-0.003844</td>\n",
       "      <td>-0.003653</td>\n",
       "      <td>-0.002709</td>\n",
       "      <td>-0.001738</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.001991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020113</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.003105</td>\n",
       "      <td>-0.002292</td>\n",
       "      <td>-0.001406</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>-0.000746</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>-0.001089</td>\n",
       "      <td>-0.000660</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>-0.001867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009234</td>\n",
       "      <td>-0.002823</td>\n",
       "      <td>-0.004967</td>\n",
       "      <td>-0.005391</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>-0.006919</td>\n",
       "      <td>-0.004537</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>-0.000579</td>\n",
       "      <td>-0.000819</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002920</td>\n",
       "      <td>-0.004015</td>\n",
       "      <td>-0.003853</td>\n",
       "      <td>-0.003008</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>-0.006323</td>\n",
       "      <td>-0.000276</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007966</td>\n",
       "      <td>-0.001643</td>\n",
       "      <td>-0.004017</td>\n",
       "      <td>-0.001746</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002357</td>\n",
       "      <td>-0.000611</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>-0.001419</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>0.009905</td>\n",
       "      <td>0.020892</td>\n",
       "      <td>0.012850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>-0.002979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.001463</td>\n",
       "      <td>-0.000950</td>\n",
       "      <td>-0.004775</td>\n",
       "      <td>-0.007005</td>\n",
       "      <td>-0.004558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.017949 -0.003000 -0.004920 -0.002380 -0.000367 -0.000958  0.000208   \n",
       "1  0.020113  0.001586  0.000428 -0.002097 -0.003105 -0.002292 -0.001406   \n",
       "2  0.009234 -0.002823 -0.004967 -0.005391 -0.005814 -0.006919 -0.004537   \n",
       "3  0.007966 -0.001643 -0.004017 -0.001746  0.000261  0.000927  0.002873   \n",
       "4  0.013393  0.000336 -0.000043  0.001852  0.005945  0.005029  0.001264   \n",
       "\n",
       "        7         8         9      ...          775       776       777  \\\n",
       "0  0.003088  0.005196  0.007890    ...    -0.001189 -0.003185 -0.004328   \n",
       "1  0.000509  0.002366  0.001386    ...     0.001184  0.000917 -0.000746   \n",
       "2  0.000360 -0.000579 -0.000819    ...    -0.002920 -0.004015 -0.003853   \n",
       "3  0.006653  0.008146  0.005505    ...    -0.002357 -0.000611  0.001283   \n",
       "4  0.001780  0.001645 -0.002979    ...     0.007261  0.005225  0.005211   \n",
       "\n",
       "        778       779       780       781       782       783       784  \n",
       "0 -0.003749 -0.003844 -0.003653 -0.002709 -0.001738  0.000456  0.001991  \n",
       "1 -0.000594 -0.000204 -0.000690 -0.001089 -0.000660 -0.001121 -0.001867  \n",
       "2 -0.003008 -0.004970 -0.006323 -0.000276 -0.000939  0.004748  0.005652  \n",
       "3 -0.001419 -0.000109  0.001210 -0.000305  0.009905  0.020892  0.012850  \n",
       "4  0.004119  0.002151  0.001463 -0.000950 -0.004775 -0.007005 -0.004558  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_data = pd.DataFrame(weights)\n",
    "weights_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_data.to_csv(\"/home/lognod/MiniML/mini_logistic_with_regularization.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 785)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.891084572788009"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(weights.shape)\n",
    "logistic_regression.validate(X_validate,Y_validate,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "weights_2 = pd.read_csv(\"/home/lognod/MiniML/mini_logistic_with_regularization.csv\")\n",
    "y = np.zeros(10)\n",
    "\n",
    "# image_array = magic.imread(\"/home/lognod/Desktop/nhcd/numerals/5/042_02.jpg\",as_gray=True)\n",
    "# pixel_data = (255.0-image_array.flatten())/255.0\n",
    "\n",
    "prediction = []\n",
    "for image in X_validate:\n",
    "    for i in range(10):\n",
    "        y[i]=logistic_regression.predict(image,weights_2.iloc[i,1:])\n",
    "    p = np.where(y == np.amax(y))\n",
    "    prediction.append(int(p[0]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= Y_validate.flatten().tolist()\n",
    "Y = list(map(int, Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(Y)):\n",
    "    if(prediction[i] == Y[i]):\n",
    "        count+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (count/len(Y)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.15972222222221"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
